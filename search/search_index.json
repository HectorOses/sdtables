{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction the tables module is intended to be consumed by other projects to prevent the need to keep rewriting data ingestion methods. Pull Requests are welcome! Example Usage Data Ingestion tables will search an Excel workbook for data defined as tables. Do define a table in Excel so Insert => Table . A table in Excel is essentially a named range of cells. It is assumed that the first row of the table contains column headers which will be used as the keys for the data in the proceeding rows; Note that the table name in Excel is globally unique for that workbook. The following code snippet will load a workbook called example_parse_xlsx.xlsx and dump the content out in YAML format. import tables import yaml excel_tables_db = 'example_parse_xlsx.xlsx' excel_to_dict = tables.load_xl_db(excel_tables_db) print(yaml.dump(excel_to_dict)) Excel Table Schema JSON schema is a standards based way to describe the structure and validation constraints of your data. Using JSON schema definition tables can auto-generate an Excel workbook containing tables representing your schema and leveraging some of Excels data validation features (E.g. enum for a list of possible values. Along with your schema you can also provide example rows of data to populate your table to guide your users. When loading the example data, tables will also try to validate it against your schema and show warnings for any validation failures. If no example data is provide tables will insert a single empty row with data validation in correct columns. Below is an example JSON schema used to define a table; properties: presence: type: string enum: ['present', 'absent'] type: type: string enum: ['area', 'building', 'floor'] name: type: string parentName: type: string latitude: type: number longitude: type: number street: type: string city: type: string country: type: string rfModel: type: string enum: ['Cubes And Walled Offices', 'Drywall Office Only', 'Indoor High Ceiling', 'Outdoor Open Space'] and here are some example rows of data; sites: - {'name': 'United States', 'parentName': 'Global', 'presence': 'present', 'type': a'} - {'name': 'Texas', 'parentName': 'Global/United States', 'presence': 'present', e': 'area'} - {'name': 'Richardson', 'parentName': 'Global/United States/Texas', 'presence': 'present', 'type': 'area'} The following code will create a new workbook text.xlsx based on this schema and example input data; import tables import yaml from openpyxl import Workbook wb = Workbook() ws = wb.active yaml_schema = \"\"\" module: name: sites methods: - create - delete - delete_all schemas: sites: properties: presence: type: string enum: ['present', 'absent'] type: type: string enum: - area - building - floor name: type: string parentName: type: string latitude: type: number longitude: type: number street: type: string city: type: string country: type: string rfModel: type: string enum: [ 'Cubes And Walled Offices', 'Drywall Office Only', 'Indoor High Ceiling', 'Outdoor Open Space' ] data: sites: - {\"presence\": \"present\", \"type\": \"area\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} - {\"presence\": \"present\", \"type\": \"area2\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} - {\"presence\": \"present\", \"type\": \"area3\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} \"\"\" dict_schema = yaml.load(yaml_schema, Loader=yaml.SafeLoader) name = '{}.{}.{}'.format('data', 'sites', 'sites') schema = dict_schema['module']['schemas']['sites'] data = dict_schema['module']['data']['sites'] tables.add_schema_table_to_worksheet(ws, name, schema, data=data, table_style='TableStyleMedium2') wb.save('test.xlsx') Note that the above example data has schema validation errors to demonstrate the validation functionality. Excel Table Data Similar to the above, we can use tables to simply create a table and populate with the provided rows of data. The first row of the data should container an empty row with all the keys that should represent each column. import tables from openpyxl import Workbook wb = Workbook() ws = wb.active name = \"sites\" data = [ {\"presence\": \"present\", \"type\": \"area\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"}, {\"presence\": \"present\", \"type\": \"area2\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"}, {\"presence\": \"present\", \"type\": \"area3\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} ] headers = { \"presence\": \"\", \"type\": \"\", \"name\": \"\", \"parentName\": \"\", \"latitude\": \"\", \"longitude\": \"\", \"street\": \"\", \"city\": \"\", \"country\": \"\", \"rfModel\": \"\" } data.insert(0, headers) tables.add_table_to_worksheet(ws, 'dataTable1', data, first_row_is_header=True, table_style='TableStyleMedium2') wb.save('test.xlsx') See also example_create_tables_from_schema Dump to Excel Uses the same format of structured data exported from \"Data Ingestion\" use case to create a complete Excel workbook. import tables data = { 'MY_NEW_WS1': { 'my_new_table': [ {'Column1': 'data1', 'Column2': 'thing1', 'Column3': 'this1', 'Column4': 'that1', 'Column5': 'other1', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data2', 'Column2': 'thing2', 'Column3': 'this2', 'Column4': 'that2', 'Column5': 'other2', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data3', 'Column2': 'thing3', 'Column3': 'this3', 'Column4': 'that3', 'Column5': 'other3', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data4', 'Column2': 'thing4', 'Column3': 'this4', 'Column4': 'that4', 'Column5': 'other4', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None} ] } } db_file_name = 'test_me.xlsx' tables.dump_db_to_xl(db_file_name, data, table_style='TableStyleMedium2', row_offset=1, col_offset=0)","title":"Tables"},{"location":"#introduction","text":"the tables module is intended to be consumed by other projects to prevent the need to keep rewriting data ingestion methods. Pull Requests are welcome!","title":"Introduction"},{"location":"#example-usage","text":"","title":"Example Usage"},{"location":"#data-ingestion","text":"tables will search an Excel workbook for data defined as tables. Do define a table in Excel so Insert => Table . A table in Excel is essentially a named range of cells. It is assumed that the first row of the table contains column headers which will be used as the keys for the data in the proceeding rows; Note that the table name in Excel is globally unique for that workbook. The following code snippet will load a workbook called example_parse_xlsx.xlsx and dump the content out in YAML format. import tables import yaml excel_tables_db = 'example_parse_xlsx.xlsx' excel_to_dict = tables.load_xl_db(excel_tables_db) print(yaml.dump(excel_to_dict))","title":"Data Ingestion"},{"location":"#excel-table-schema","text":"JSON schema is a standards based way to describe the structure and validation constraints of your data. Using JSON schema definition tables can auto-generate an Excel workbook containing tables representing your schema and leveraging some of Excels data validation features (E.g. enum for a list of possible values. Along with your schema you can also provide example rows of data to populate your table to guide your users. When loading the example data, tables will also try to validate it against your schema and show warnings for any validation failures. If no example data is provide tables will insert a single empty row with data validation in correct columns. Below is an example JSON schema used to define a table; properties: presence: type: string enum: ['present', 'absent'] type: type: string enum: ['area', 'building', 'floor'] name: type: string parentName: type: string latitude: type: number longitude: type: number street: type: string city: type: string country: type: string rfModel: type: string enum: ['Cubes And Walled Offices', 'Drywall Office Only', 'Indoor High Ceiling', 'Outdoor Open Space'] and here are some example rows of data; sites: - {'name': 'United States', 'parentName': 'Global', 'presence': 'present', 'type': a'} - {'name': 'Texas', 'parentName': 'Global/United States', 'presence': 'present', e': 'area'} - {'name': 'Richardson', 'parentName': 'Global/United States/Texas', 'presence': 'present', 'type': 'area'} The following code will create a new workbook text.xlsx based on this schema and example input data; import tables import yaml from openpyxl import Workbook wb = Workbook() ws = wb.active yaml_schema = \"\"\" module: name: sites methods: - create - delete - delete_all schemas: sites: properties: presence: type: string enum: ['present', 'absent'] type: type: string enum: - area - building - floor name: type: string parentName: type: string latitude: type: number longitude: type: number street: type: string city: type: string country: type: string rfModel: type: string enum: [ 'Cubes And Walled Offices', 'Drywall Office Only', 'Indoor High Ceiling', 'Outdoor Open Space' ] data: sites: - {\"presence\": \"present\", \"type\": \"area\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} - {\"presence\": \"present\", \"type\": \"area2\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} - {\"presence\": \"present\", \"type\": \"area3\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} \"\"\" dict_schema = yaml.load(yaml_schema, Loader=yaml.SafeLoader) name = '{}.{}.{}'.format('data', 'sites', 'sites') schema = dict_schema['module']['schemas']['sites'] data = dict_schema['module']['data']['sites'] tables.add_schema_table_to_worksheet(ws, name, schema, data=data, table_style='TableStyleMedium2') wb.save('test.xlsx') Note that the above example data has schema validation errors to demonstrate the validation functionality.","title":"Excel Table Schema"},{"location":"#excel-table-data","text":"Similar to the above, we can use tables to simply create a table and populate with the provided rows of data. The first row of the data should container an empty row with all the keys that should represent each column. import tables from openpyxl import Workbook wb = Workbook() ws = wb.active name = \"sites\" data = [ {\"presence\": \"present\", \"type\": \"area\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"}, {\"presence\": \"present\", \"type\": \"area2\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"}, {\"presence\": \"present\", \"type\": \"area3\", \"name\": \"United States\", \"parentName\": \"Global\", \"rfModel\": \"Cubes And Walled Offices\"} ] headers = { \"presence\": \"\", \"type\": \"\", \"name\": \"\", \"parentName\": \"\", \"latitude\": \"\", \"longitude\": \"\", \"street\": \"\", \"city\": \"\", \"country\": \"\", \"rfModel\": \"\" } data.insert(0, headers) tables.add_table_to_worksheet(ws, 'dataTable1', data, first_row_is_header=True, table_style='TableStyleMedium2') wb.save('test.xlsx') See also example_create_tables_from_schema","title":"Excel Table Data"},{"location":"#dump-to-excel","text":"Uses the same format of structured data exported from \"Data Ingestion\" use case to create a complete Excel workbook. import tables data = { 'MY_NEW_WS1': { 'my_new_table': [ {'Column1': 'data1', 'Column2': 'thing1', 'Column3': 'this1', 'Column4': 'that1', 'Column5': 'other1', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data2', 'Column2': 'thing2', 'Column3': 'this2', 'Column4': 'that2', 'Column5': 'other2', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data3', 'Column2': 'thing3', 'Column3': 'this3', 'Column4': 'that3', 'Column5': 'other3', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None}, {'Column1': 'data4', 'Column2': 'thing4', 'Column3': 'this4', 'Column4': 'that4', 'Column5': 'other4', 'Column6': None, 'Column7': None, 'Column8': None, 'Column9': None, 'Column10': None, 'Column11': None, 'Column12': None, 'Column13': None, 'Column14': None, 'Column15': None} ] } } db_file_name = 'test_me.xlsx' tables.dump_db_to_xl(db_file_name, data, table_style='TableStyleMedium2', row_offset=1, col_offset=0)","title":"Dump to Excel"},{"location":"MKDocs/","text":"Document Generation In order to generate documentation for the DNA Workflows project we are using a mixture of mkdocs and pydoc-markdown which can both both installed locally using pip; pip3 install pydoc-markdown pip3 install mkdocs Static page documentation is created in Markdown format and stored in ./docs along with the configuration file for pydoc-markdown . pydoc-markdown creates a wrapper for generating the mkdocs configuration whilst at the same time generating documentation from the python doc strings in the DNA Workflows modules. The workflow for updating the documentation here goes something like this; Add new .md files to the ./docs folder and index them in the ./docs/pydoc-markdown.yml Ensure that you have good doc strings in your DNA Workflow modules and then also add that module to the ./docs/pydoc-markdown.yml Run the pydoc-markdown script using the ./docs/pydoc-markdown.yml pydoc-markdown docs/pydoc-markdown.yml This will create a new ./build directory which will be ignored by .gitignore but contains everything mkdocs needs to generate the new site. We use the dedicated gh-pages branch to publish our documentation using this same repo. mkdocs will autogenerate the site HTML and create/update this dedicated branch; mkdocs gh-deploy -f build/docs/mkdocs.yml For locall testing you can also use the -wo options to start a local web server to and browse the generated pages; pydoc-markdown docs/pydoc-markdown.yml -wo WARNING: pydoc-markdown``` does not copy the ./media files from ```./docs/media``` so it is necessary to also do this intermediate step also. The full script should be (run from the project root dir); pydoc-markdown docs/pydoc-markdown.yml cp -r docs/media build/docs/docs/ mkdocs gh-deploy -f build/docs/mkdocs.yml ``` Or you can simply run the builddocs.sh script.","title":"MKDocs"},{"location":"MKDocs/#document-generation","text":"In order to generate documentation for the DNA Workflows project we are using a mixture of mkdocs and pydoc-markdown which can both both installed locally using pip; pip3 install pydoc-markdown pip3 install mkdocs Static page documentation is created in Markdown format and stored in ./docs along with the configuration file for pydoc-markdown . pydoc-markdown creates a wrapper for generating the mkdocs configuration whilst at the same time generating documentation from the python doc strings in the DNA Workflows modules. The workflow for updating the documentation here goes something like this; Add new .md files to the ./docs folder and index them in the ./docs/pydoc-markdown.yml Ensure that you have good doc strings in your DNA Workflow modules and then also add that module to the ./docs/pydoc-markdown.yml Run the pydoc-markdown script using the ./docs/pydoc-markdown.yml pydoc-markdown docs/pydoc-markdown.yml This will create a new ./build directory which will be ignored by .gitignore but contains everything mkdocs needs to generate the new site. We use the dedicated gh-pages branch to publish our documentation using this same repo. mkdocs will autogenerate the site HTML and create/update this dedicated branch; mkdocs gh-deploy -f build/docs/mkdocs.yml For locall testing you can also use the -wo options to start a local web server to and browse the generated pages; pydoc-markdown docs/pydoc-markdown.yml -wo WARNING: pydoc-markdown``` does not copy the ./media files from ```./docs/media``` so it is necessary to also do this intermediate step also. The full script should be (run from the project root dir); pydoc-markdown docs/pydoc-markdown.yml cp -r docs/media build/docs/docs/ mkdocs gh-deploy -f build/docs/mkdocs.yml ``` Or you can simply run the builddocs.sh script.","title":"Document Generation"},{"location":"modules/","text":"","title":"Modules"}]}